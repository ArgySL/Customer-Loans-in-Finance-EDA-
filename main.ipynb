{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Customer Loans In Finance\n",
    "\n",
    "## Aim\n",
    "1. Identify outliers, assess skewness, understand types of missing data, and explore correlations within the dataset.\n",
    "2. Transform the data to ensure correct data types, promote normal distribution, and impute missing values.\n",
    "3. Analyze the transformed loan data to identify emerging patterns and enhance loan risk management strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_utils import load_credentials, RDSDatabaseConnector\n",
    "import matplotlib.pyplot as pyplot\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "\n",
    "from format import DataFormat\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from plotter import Plotter\n",
    "\n",
    "\n",
    "from transform import DataFrameTransform\n",
    "\n",
    "\n",
    "from db_utils import load_data\n",
    "\n",
    "\n",
    "from info import DataFrameInfo\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check percentage of missing columns and Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(\"loan_payments.csv\")\n",
    "info = DataFrameInfo(df)\n",
    "\n",
    "print(info.get_shape())\n",
    "print(info.percentage_null())\n",
    "\n",
    "plt = Plotter(df)\n",
    "\n",
    "plt.missing_nulls_vis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating Data to appropriate types based on held information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings to Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer = DataFormat(df)\n",
    "# Convert n and y to bool values\n",
    "Transformer.string_to_boolean('payment_plan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings to Date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String dates to date format\n",
    "string_dates = ['last_credit_pull_date', 'next_payment_date',\n",
    "                'last_payment_date', 'earliest_credit_line', 'issue_date']\n",
    "\n",
    "Transformer.strings_to_dates(string_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String to number strip\n",
    "\n",
    "**(Note)...**\n",
    "We don't convert these columns : 'mths_since_last_record', 'mths_since_last_major_derog' to int since they include 0 months since last to tell recent entry and null for NO entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_num_cols = ['term', 'employment_length']\n",
    "numerical_cols = ['term', 'mths_since_last_record',\n",
    "                  'mths_since_last_major_derog', 'mths_since_last_delinq', 'mths_since_last_record', 'delinq_2yrs']\n",
    "\n",
    "# Month to integer\n",
    "Transformer.extract_num_from_string(string_to_num_cols)\n",
    "\n",
    "Transformer.numerical_cols(numerical_cols)\n",
    "\n",
    "Transformer.to_int(['term', 'open_accounts', 'total_accounts',\n",
    "                    'collections_12_mths_ex_med', 'delinq_2yrs', 'employment_length', 'funded_amount'])\n",
    "\n",
    "Transformer.round_float('collection_recovery_fee', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Final Payment Date (needed for calculating projected loss later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer.df['final_payment_date'] = Transformer.df.apply(\n",
    "    lambda row: row['issue_date'] + DateOffset(months=row['term']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Categorical columns\n",
    "\n",
    "**(Note)...**\n",
    "#### Also Handle NMCAR values into bin categories\n",
    "These are NMCAR because they tell that users do not have a negative loan history \n",
    "\n",
    "1. months_since_last_delinq 57.17\n",
    "2. months_since_last_record 88.60\n",
    "3. months_since_last_major_derog  86.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [np.nan, 0, 36, 72, 108, 146]\n",
    "bin_labels = ['Never', '1-3 Years',\n",
    "              '4-6 Years', '7-9 Years', '10-12 Years']\n",
    "\n",
    "bin_cols = ['months_since_last_delinq', 'months_since_last_record',\n",
    "            'months_since_last_major_derog']\n",
    "\n",
    "for col in bin_cols:\n",
    "    Transformer.df[col] = pd.cut(Transformer.df[col], bins=bins,\n",
    "                                 labels=bin_labels, right=True, include_lowest=True)\n",
    "    Transformer.df[col] = Transformer.df[col].fillna('Never')\n",
    "\n",
    "\n",
    "categories = ['grade', 'sub_grade', 'home_ownership',\n",
    "              'verification_status', 'loan_status', 'purpose', 'employment_length']\n",
    "\n",
    "Transformer.cols_to_categories(categories)\n",
    "Transformer.cols_to_categories(bin_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application and policy code have all same values across their whole columns\n",
    "# out_prncp_inv/total_payment_inv is the same as out_prncp/total_payment\n",
    "# next_payment_date doesn't seem useful to us since there are a lot missing values (possibly NMAR because suggest payed off loan)\n",
    "\n",
    "drop_cols = ['application_type',\n",
    "             'policy_code', 'out_prncp_inv', 'total_payment_inv', 'Unnamed: 0', 'id', 'next_payment_date'\n",
    "             ]\n",
    "Transformer.drop_cols(drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing values with appropriate methods\n",
    "\n",
    "**(Note)...**\n",
    "\n",
    "1. Missing *employment length* likely means unemployed so impute 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute and further drop\n",
    "\n",
    "t_form = DataFrameTransform(df)\n",
    "\n",
    "# Assume When Employment length is missing it means they don't have a job\n",
    "t_form.impute_zeros(['employment_length'])\n",
    "# mean interest rate since its within normal dist\n",
    "t_form.impute_median(['int_rate', 'loan_amount', 'funded_amount'])\n",
    "\n",
    "# these rows have insignificant null vals\n",
    "t_form.drop_null_rows(['last_payment_date', 'last_credit_pull_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show cleaned and imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = Plotter(t_form.df)\n",
    "plt.missing_nulls_vis()\n",
    "\n",
    "# Save Data\n",
    "RDSDatabaseConnector.save_to_csv(\n",
    "    t_form.df, \"formatted_loan_payments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Skew of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# delinq appears more discrete than continuous so it's not included in skew analysis\n",
    "numerical_cols = ['loan_amount',\n",
    "                  'funded_amount_inv', 'int_rate', 'instalment', 'dti', 'annual_inc', 'total_payment', 'total_accounts', 'open_accounts', 'last_payment_amount']\n",
    "\n",
    "plt.multi_hist_plot(numerical_cols)\n",
    "Info.skew_data(numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Skew Result\n",
    "All numerical data displays a high positive skew, signifying a substantial overrepresentation of values by outliers. Additionally, both the mean and median significantly exceed the mode, indicating a pronounced asymmetry in the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.multi_qq_plot(numerical_cols)\n",
    "\n",
    "info = DataFrameInfo(t_form.df)\n",
    "\n",
    "right_skewed_cols = ['annual_inc', 'total_payment', 'total_accounts',\n",
    "                     'last_payment_amount', 'open_accounts', 'instalment', 'funded_amount_inv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " * Noticing that a significant number of columns display outliers characterized by an almost exponential pattern. The skew values have now moved closer to 0, suggesting a more balanced distribution, making it suitable for implementing the Box-Cox transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_form.box_cox_transform(\n",
    "    ['loan_amount', 'instalment', 'int_rate', 'dti', 'funded_amount_inv', 'total_payment'])\n",
    "\n",
    "# Reduce impact of outliers\n",
    "log_transform_cols = ['annual_inc', 'total_accounts',\n",
    "                      'open_accounts', 'last_payment_amount']\n",
    "\n",
    "t_form.log_transform(log_transform_cols)\n",
    "\n",
    "Info.skew_data(\n",
    "    ['loan_amount', 'total_payment', 'instalment', 'int_rate', 'dti', 'funded_amount_inv', 'annual_inc', 'total_accounts', 'open_accounts', 'last_payment_amount'])\n",
    "\n",
    "\n",
    "plt.multi_hist_plot(numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now the data exhibits a more normal distribution, making it suitable for linear regression, k-nearest neighbors, and SVM algorithms. Certain features, such as total_accounts and open_accounts, appear more discretely represented in the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.multi_qq_plot(numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure of Correlation of data to understand which columns are redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "plt.correlated_vars(numerical_cols)\n",
    "\n",
    "model0 = smf.ols(\"funded_amount ~ funded_amount_inv\", plt.df).fit()\n",
    "\n",
    "\n",
    "def VIF(r2):\n",
    "    return 1/(1-r2)\n",
    "\n",
    "\n",
    "print(VIF(model0.rsquared))\n",
    "RDSDatabaseConnector.save_to_csv(\n",
    "    t_form.df, \"transformed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current State of Loans\n",
    "\n",
    "1. Summarizing the Current Recovery Rate Against Investor Funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"formatted_payments.csv\",\n",
    "                 parse_dates=['issue_date', 'last_payment_date', 'final_payment_date'])\n",
    "\n",
    "df['final_payment_date'] = df.apply(\n",
    "    lambda row: row['issue_date'] + DateOffset(months=row['term']), axis=1)\n",
    "df['total_to_pay'] = df['instalment'] * \\\n",
    "    df['term']\n",
    "\n",
    "no_nill_invested = df['funded_amount_inv'] != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If null for funded_amount_inv (investors) use funded_amount (business)\n",
    "original_df = df[~no_nill_invested]\n",
    "\n",
    "df = df[no_nill_invested]\n",
    "\n",
    "# Check If the loan is recovered\n",
    "df['recovered_ratio'] = (\n",
    "    df['total_payment'] / df['funded_amount_inv'])\n",
    "\n",
    "original_df['recovered_ratio'] = (\n",
    "    original_df['total_payment'] / df['funded_amount'])\n",
    "\n",
    "# Recombine dataframes now with ratio\n",
    "df = pd.concat([df, original_df], ignore_index=True)\n",
    "\n",
    "# Convert to index for grouping\n",
    "df['last_payment_date'] = pd.DatetimeIndex(df['last_payment_date'])\n",
    "\n",
    "# Check if loan is recovered\n",
    "df['recovered'] = df['recovered_ratio'].ge(1)\n",
    "recovered_loans = df['recovered'] == True\n",
    "\n",
    "# Filter by recovered loans\n",
    "recovered_loan_df = df[recovered_loans]\n",
    "\n",
    "percent_of_loans_recovered = round(len(recovered_loan_df) / len(df) * 100, 2)\n",
    "\n",
    "print(f\"Percent of Loans Currently Recovered: {percent_of_loans_recovered}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Projecting the Query 6 Months in the Future Based on Monthly Installments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what kind of further data can be recovered in 6 months' time\n",
    "\n",
    "finished_term_mask = df['final_payment_date'] > df['last_payment_date']\n",
    "future_df = df.loc[~recovered_loans & finished_term_mask].copy()\n",
    "\n",
    "\n",
    "prediction_df = df.loc[~recovered_loans & finished_term_mask].copy()\n",
    "prediction_recovered_df = df.loc[recovered_loans].copy()\n",
    "\n",
    "prediction_df['recovered'] = 0\n",
    "future_df['6m_future_total_payment'] = future_df['total_payment'] + \\\n",
    "    (future_df['instalment'] * 6)\n",
    "\n",
    "\n",
    "future_df['recovered'] = (\n",
    "    future_df['6m_future_total_payment'] / df['funded_amount_inv']).ge(1)\n",
    "\n",
    "\n",
    "recovered_loans = future_df['recovered'] == True\n",
    "recovered_loan_df_6m_future = future_df.loc[recovered_loans]\n",
    "\n",
    "\n",
    "percent_of_loans_recovered = round(\n",
    "    len(recovered_loan_df_6m_future) / len(df) * 100, 2)\n",
    "\n",
    "\n",
    "print(f\"Percent of Loans Currently Recovered: {percent_of_loans_recovered}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating and Graphing the future 6 month payments\n",
    "\n",
    "3. An additional 15% of loans is assumed to be recovered based on installment payments. To visualize this insight, simulated data is created and graphed.\n",
    "\n",
    "### Thought Process\n",
    "The dataframe is initially separated into recovered and unrecovered slices to determine what percentage of the unrecovered dataframe could be paid off in 6 months.\n",
    "\n",
    "The following steps were taken:\n",
    "\n",
    "1. Set all the last payment dates to the latest date.\n",
    "2. Slice only the rows with the latest date (initially, this is all the rows).\n",
    "3. Add the total_payment and installment and increment the month by 1 to get simulated next month's payment.\n",
    "4. The next iteration would select this last slice because it's the latest date and continue until 6 months.\n",
    "\n",
    "(This process is similar to a window function per date.)\n",
    "\n",
    "This approach was chosen to showcase the cumulative sum of the percentage change over months in recovered loans and visualize it in a graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = prediction_df[[\n",
    "    'last_payment_date', 'total_payment', 'instalment', 'funded_amount_inv', 'member_id', 'recovered']]\n",
    "\n",
    "\n",
    "def add_months(df, col, nmonths):\n",
    "    df[col] = df[col] + DateOffset(months=nmonths)\n",
    "\n",
    "\n",
    "def add_nums(df, col, col_2):\n",
    "    df[col] = df[col] + df[col_2]\n",
    "\n",
    "\n",
    "def copy_and_mask_df(df, mask):\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "\n",
    "# Simulate payments and dates\n",
    "months_to_predict = 6\n",
    "\n",
    "prediction_df.sort_values(\n",
    "    by='last_payment_date', ascending=False, inplace=True)\n",
    "\n",
    "# reset all values to be the latest date payment was made\n",
    "prediction_df['last_payment_date'] = prediction_df['last_payment_date'].iloc[0]\n",
    "\n",
    "# dataframe used for prediction\n",
    "for _ in range(months_to_predict):\n",
    "    latest_date = prediction_df['last_payment_date'].max()\n",
    "\n",
    "    mask = (prediction_df['last_payment_date'] == latest_date) & (\n",
    "        prediction_df['recovered'] == False)\n",
    "\n",
    "    copy_df = copy_and_mask_df(prediction_df, mask)\n",
    "\n",
    "    add_nums(copy_df, 'total_payment', 'instalment')\n",
    "    add_months(copy_df, 'last_payment_date', 1)\n",
    "\n",
    "    copy_df['recovered'] = (\n",
    "        copy_df['total_payment'] / copy_df['funded_amount_inv']) >= 1\n",
    "\n",
    "    prediction_df = pd.concat([prediction_df, copy_df], ignore_index=True)\n",
    "\n",
    "\n",
    "min_date = prediction_df['last_payment_date'].min()\n",
    "prediction_df = prediction_df[prediction_df['last_payment_date'] > min_date]\n",
    "prediction_df = prediction_df[prediction_df['recovered'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.concat(\n",
    "    [prediction_recovered_df, prediction_df], ignore_index=True)\n",
    "\n",
    "# Group by month to count amount recovered that month\n",
    "filtered_df = complete_df .set_index('last_payment_date').groupby(\n",
    "    [pd.Grouper(freq=\"M\")])['recovered'].count().reset_index()\n",
    "\n",
    "# Sort by date\n",
    "filtered_df.sort_values(\n",
    "    by='last_payment_date', ascending=True, inplace=True)\n",
    "\n",
    "# Cumulative sum the percentage recovered per month ( recovered count / total recovered + unrecovered count )\n",
    "filtered_df['cumulative_sum'] = filtered_df['recovered'].apply(\n",
    "    lambda x: x / (len(df)) * 100).cumsum()\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As observed, we have the anticipated final sum based on the previously calculated values:\n",
    "    Percent of Loans Currently Recovered: 55.98% + Percent of Loans Currently Recovered: 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_original_data = filtered_df['last_payment_date'] <= min_date\n",
    "mask_future_data = filtered_df['last_payment_date'] >= min_date - \\\n",
    "    DateOffset(months=1)\n",
    "\n",
    "original_df = filtered_df.loc[mask_original_data]\n",
    "future_df = filtered_df.loc[mask_future_data]\n",
    "\n",
    "pyplot.plot(original_df['last_payment_date'],\n",
    "            original_df['cumulative_sum'], label='Recovered so far')\n",
    "pyplot.plot(future_df['last_payment_date'],\n",
    "            future_df['cumulative_sum'], label='Recovered in 6 months')\n",
    "\n",
    "pyplot.legend()\n",
    "pyplot.title('Current vs Future Recovered Loans')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Loss\n",
    "\n",
    "Via column *loan_status* on loans that are charged_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ormatted_payments.csv\",\n",
    "                 parse_dates=['issue_date', 'last_payment_date', 'final_payment_date'])\n",
    "\n",
    "\n",
    "charged_off_mask = df['loan_status'] == 'Charged Off'\n",
    "\n",
    "\n",
    "\n",
    "charged_off_df = df.loc[charged_off_mask].copy()\n",
    "\n",
    "\n",
    "\n",
    "prc_charged_off = round((len(charged_off_df) / len(df)) * 100, 2)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Percentage Charged Off : {prc_charged_off}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_off_df['expected_total_payment'] = charged_off_df['instalment'] * \\\n",
    "    charged_off_df['term']\n",
    "\n",
    "total_paid = round(sum(charged_off_df['total_payment']), 2)\n",
    "\n",
    "total_required = round(sum(charged_off_df['expected_total_payment']), 2)\n",
    "\n",
    "prc_paid_off = round((total_paid / total_required) * 100, 2)\n",
    "\n",
    "print(f\"Paid Towards Charged Off: {total_paid}\")\n",
    "print(f\"Required to be paid: {total_required}\")\n",
    "print(f\"Percentage paid off: {prc_paid_off}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalments already include interest\n",
    "\n",
    "missed_out_revenue = round(total_required - total_paid, 2)\n",
    "prc_lost = round((missed_out_revenue / total_required) * 100, 2)\n",
    "\n",
    "print(f\"Missed out/ Increase in revenue: ${missed_out_revenue}\")\n",
    "print(f\"Percentage Lost: {prc_lost}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payments_made'] = df['total_payment'] / \\\n",
    "    df['instalment']\n",
    "df['months_left_to_pay'] = df['term'] - \\\n",
    "    df['payments_made']\n",
    "\n",
    "late_mask = df['loan_status'].str.contains('Late')\n",
    "\n",
    "late_df = df.loc[late_mask].copy()\n",
    "\n",
    "prc_behind = round((len(late_df) / len(df)) * 100, 2)\n",
    "\n",
    "print(f\"Percentage of Late Loans: {prc_behind}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_df['amount_left_to_pay'] = late_df['months_left_to_pay'] * \\\n",
    "    late_df['instalment']\n",
    "\n",
    "projected_loss = round(late_df['amount_left_to_pay'].sum(), 2)\n",
    "\n",
    "print(f\"Projected Loss if Switched to Charged Off: ${projected_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_late_and_charged_off = round(\n",
    "    ((len(late_df) + len(charged_off_df)) / len(df)) * 100, 2)\n",
    "\n",
    "print(\n",
    "    f\"Percentage of late and charged_off customers: {prc_late_and_charged_off}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicator of Loss\n",
    "\n",
    "Analyzing Potential Indicators of Loan Default\n",
    "\n",
    "Identifying Data Points for Examination:\n",
    "\n",
    "Highlight Data to Check\n",
    "1. Loan Grade\n",
    "2. Reason\n",
    "3. DTI (Debt-to-Income Ratio)\n",
    "\n",
    "Initially, the categorical columns will be converted to numerical representations to facilitate their application to the correlation matrix and Chi-Squared test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_and_charged_off = pd.concat([late_df, charged_off_df])\n",
    "\n",
    "categorical_cols = df.select_dtypes(\n",
    "    exclude=np.number).columns.tolist()\n",
    "\n",
    "_, b = pd.factorize(df[categorical_cols].values.ravel('F'))\n",
    "\n",
    "df[categorical_cols] = df[categorical_cols].apply(\n",
    "    lambda x: pd.Categorical(x, b).codes)\n",
    "\n",
    "\n",
    "indicator_cols = ['grade', 'sub_grade', 'purpose',\n",
    "                  'dti', 'delinq_2yrs', 'employment_length', 'last_payment_amount', 'loan_status']\n",
    "\n",
    "plt = Plotter(df)\n",
    "plt.correlated_vars(indicator_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_table = pd.crosstab(df['grade'], df['loan_status'])\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-square statistic = {chi2}\")\n",
    "print(f\"p-value = {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss prediction result\n",
    "\n",
    "\n",
    "# Correlation Matrix\n",
    "The correlation matrix indicates minimal correlation between the loan_status and any anticipated factors. Consequently, we won't be isolating a subset of charged-off customers for further exploration.\n",
    "\n",
    "# Chi-Squared Test\n",
    "The Chi-Squared Test reveals a remarkably high statistic and a p-value of 0, indicating a substantial difference among potential indicator columns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
